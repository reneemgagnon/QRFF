<p align="center">
  <img src="https://img.shields.io/badge/ğŸ”®_Quaternion-Ruffle_Field-blueviolet?style=for-the-badge&labelColor=1a1a2e" alt="Quaternion Ruffle Field"/>
</p>

<h1 align="center">
  Quaternion Ruffle Field
</h1>

<h3 align="center">
  <em>A Novel Neural Architecture Where Neurons Know Which Way They're Pointing</em>
</h3>

<p align="center">
  <a href="https://pytorch.org/">
    <img src="https://img.shields.io/badge/PyTorch-2.0+-ee4c2c?style=flat-square&logo=pytorch&logoColor=white" alt="PyTorch">
  </a>
  <a href="https://www.python.org/">
    <img src="https://img.shields.io/badge/Python-3.9+-3776ab?style=flat-square&logo=python&logoColor=white" alt="Python">
  </a>
  <a href="LICENSE">
    <img src="https://img.shields.io/badge/License-MIT-green?style=flat-square" alt="License">
  </a>
  <a href="#">
    <img src="https://img.shields.io/badge/Build-Passing-brightgreen?style=flat-square&logo=github-actions" alt="Build">
  </a>
  <a href="#">
    <img src="https://img.shields.io/badge/Rotation_Accuracy-92.6%25-gold?style=flat-square" alt="Accuracy">
  </a>
</p>

<p align="center">
  <a href="#-key-innovation">Innovation</a> â€¢
  <a href="#-benchmark-results">Benchmarks</a> â€¢
  <a href="#-installation">Installation</a> â€¢
  <a href="#-quick-start">Quick Start</a> â€¢
  <a href="#-architecture">Architecture</a> â€¢
  <a href="#-citation">Citation</a>
</p>

---

## ğŸ† Headline Results

<table>
<tr>
<td align="center" width="50%">

### 3D Rotation Prediction

| Model | Accuracy | Parameters |
|:------|:--------:|:----------:|
| **QRF (Ours)** | **92.6%** | 152K |
| QRF (No Attention) | 87.4% | 131K |
| Dense MLP | 85.4% | 18K |
| Transformer | 78.6% | 398K |
| LSTM | 71.8% | 202K |

</td>
<td align="center" width="50%">

### ğŸ¥‡ QRF Wins!

**+7.2%** over best baseline

**2.6x fewer** parameters than Transformer

**Quaternions naturally encode rotation** â€” QRF leverages this inductive bias

</td>
</tr>
</table>

---

## ğŸŒŸ What is Quaternion Ruffle Field?

**Quaternion Ruffle Field (QRF)** is a novel neural network architecture where each neuron maintains both a **spatial position** and a **rotational orientation** represented as a unit quaternion. Unlike traditional scalar neurons, QRF neurons exist on a dynamic manifold (SÂ³) and interact through geometric relationships.

<table>
<tr>
<td width="50%">

### ğŸ§  Traditional Neuron
```
Value: 0.73
```
Just a number. No direction. No orientation memory.

</td>
<td width="50%">

### ğŸ”® Quaternion Neuron
```
Position:    [x, y, z, w] âˆˆ â„â´
Orientation: q = w + xi + yj + zk âˆˆ SÂ³
```
A point in space **that knows which way it's pointing!**

</td>
</tr>
</table>

### ğŸ’¡ The Core Insight

Traditional neural networks treat rotation as just another pattern to learn. QRF **builds rotation into the neuron itself** â€” each neuron IS a rotation. This creates a powerful inductive bias for tasks involving 3D geometry, orientation, and rotational relationships.

---

## ğŸš€ Key Features

<table>
<tr>
<td align="center" width="20%">
<h3>ğŸ”„</h3>
<b>Dual-State Neurons</b>
<br><sub>Position + Orientation</sub>
</td>
<td align="center" width="20%">
<h3>ğŸŒ¡ï¸</h3>
<b>Field Thermodynamics</b>
<br><sub>Adaptive Temperature & Coherence</sub>
</td>
<td align="center" width="20%">
<h3>ğŸ§ </h3>
<b>Sequence Memory</b>
<br><sub>Cross-Timestep Attention</sub>
</td>
<td align="center" width="20%">
<h3>ğŸ’¾</h3>
<b>SLERP Memory</b>
<br><sub>Spherical Interpolation</sub>
</td>
<td align="center" width="20%">
<h3>âš¡</h3>
<b>Ruffle Optimizer</b>
<br><sub>Energy-Based Exploration</sub>
</td>
</tr>
</table>

### âœ¨ What Makes QRF Different

| Feature | Traditional NN | QRF | Benefit |
|---------|---------------|-----|---------|
| **Neuron State** | Scalar value | Position + Quaternion | Native rotation representation |
| **Interactions** | Matrix multiply | Hamilton products + Geodesics | Preserves rotational composition |
| **Attention** | Learned from scratch | Modulated by quaternion state | Geometry-aware weighting |
| **Memory** | Hidden states | SLERP on SÂ³ manifold | Smooth orientation interpolation |
| **Dynamics** | Static weights | Temperature + Coherence evolution | Automatic regularization |
| **Optimization** | Gradient only | Gradient + Ruffle perturbations | Escapes local minima |

---

## ğŸ“Š Benchmark Results

### Task 1: 3D Rotation Prediction

Given 64 noisy point correspondences (before/after rotation), predict the rotation quaternion.

```
Model              Accuracy    Params      Time(s)    
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ¥‡ QRF             92.60%      151,641     180.1      
ğŸ¥ˆ QRF_NoAttn      87.40%      131,077     163.5      
ğŸ¥‰ Dense           85.40%      18,436      32.9       
   Transformer     78.60%      398,212     502.0      
   LSTM            71.80%      202,500     138.6      
```

**Why QRF excels:** Quaternions naturally compose rotations. The sequence memory aggregates evidence from all 64 point pairs simultaneously.

### Task 2: Long-Term Memory

Remember a pattern from sequence start, recall after noise-filled gap.

```
Model              Accuracy    Params      
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   Transformer     100.0%      413,828     
   LSTM            100.0%      264,964     
   QRF             100.0%      167,257     
   QRF_NoAttn      100.0%      146,693     
   Dense           58.6%       34,052      
```

**Note:** QRF matches Transformer/LSTM with **2.5x fewer parameters**.

### Task 3: Sequence Classification

Classify sequences based on embedded prototype patterns.

```
Model              Accuracy    Params      
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   All models      100.0%      Various     
```

All models solve this task perfectly â€” it's included as a sanity check.

### Field Dynamics (What Makes QRF Unique)

During training, QRF's field state evolves:

```
Metric          Start       End         Meaning
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Energy          ~1.3        0.93        Field becoming more organized
Temperature     1.0         0.51        Cooling â†’ sharper decisions
Coherence       1.0         0.58        Neurons aligning orientations
```

These dynamics provide **automatic regularization** â€” the field self-organizes!

---

## ğŸ“¦ Installation

### Prerequisites

Python 3.9+ and PyTorch 2.0+

### Via pip

```bash
pip install quaternion-ruffle-field
```

### From Source

```bash
git clone https://github.com/yourusername/quaternion-ruffle-field.git
cd quaternion-ruffle-field
pip install -e .
```

### Requirements

```txt
torch>=2.0.0
numpy>=1.24.0
```

---

## âš¡ Quick Start

### Basic Usage

```python
import torch
from quaternion_ruffle_field import QRFModel

# Create model for rotation prediction (output_dim=4 for quaternion)
model = QRFModel(
    input_dim=6,           # e.g., 3D point + rotated point
    hidden_dim=128,
    output_dim=4,          # quaternion output
    n_neurons=64,
    use_attention=True,
    use_sequence_memory=True  # NEW in v5.0!
)

# Forward pass
x = torch.randn(32, 64, 6)  # [batch, sequence, features]
quaternions = model(x)       # [batch, sequence, 4] - unit quaternions!

print(f"Output shape: {quaternions.shape}")
print(f"Is unit quaternion: {torch.allclose(quaternions.norm(dim=-1), torch.ones(32, 64))}")
```

### With Ruffle Optimization

```python
from quaternion_ruffle_field import QRFModel, QuaternionRuffleOptimizer

model = QRFModel(input_dim=6, hidden_dim=128, output_dim=4, n_neurons=64)
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)
qrf_optimizer = QuaternionRuffleOptimizer(model.field, fold_threshold=1.5)

for epoch in range(30):
    for batch in dataloader:
        optimizer.zero_grad()
        
        output = model(batch['input'])
        loss = quaternion_loss(output, batch['target'])
        
        loss.backward()
        optimizer.step()
        
        # Apply quaternion ruffles (energy-based perturbations)
        stats = qrf_optimizer.step()
    
    print(f"Epoch {epoch}: Energy={stats['energy']:.3f}, T={stats['temperature']:.3f}")
```

### Memory-Aware Processing

```python
# Process first sequence
out1 = model(sequence_1)

# Reset field but preserve learned state
model.field.reset(preserve_memory=True)

# Process second sequence (can recall previous context)
out2 = model(sequence_2)

# Explicitly restore from memory with SLERP blending
model.field.restore_from_memory(blend_factor=0.5)
```

---

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         QUATERNION RUFFLE FIELD v5.0                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                               â”‚
â”‚  INPUT                    SEQUENCE MEMORY                  FIELD PROCESSING  â”‚
â”‚  â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                                               â”‚
â”‚  [batch, seq, dim]   â”€â”€â–º  Cross-Timestep    â”€â”€â–º  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                           Attention               â”‚  Quaternion Field   â”‚    â”‚
â”‚                           (Q, K, V)               â”‚  â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”Œâ”€â”€â”€â” â”‚    â”‚
â”‚                           â”‚                       â”‚  â”‚ q â”‚ â”‚ q â”‚ â”‚ q â”‚ â”‚    â”‚
â”‚                           â–¼                       â”‚  â””â”€â”¬â”€â”˜ â””â”€â”¬â”€â”˜ â””â”€â”¬â”€â”˜ â”‚    â”‚
â”‚                     Temperature-                  â”‚    â”‚     â”‚     â”‚   â”‚    â”‚
â”‚                     Modulated                     â”‚    â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚                     Softmax                       â”‚    Hamilton Productsâ”‚    â”‚
â”‚                           â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                           â–¼                                  â”‚               â”‚
â”‚                     Gated Memory                             â–¼               â”‚
â”‚                     Integration              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                           â”‚                  â”‚   Quaternion Modulation   â”‚   â”‚
â”‚                           â”‚                  â”‚   + Cached Attention      â”‚   â”‚
â”‚                           â”‚                  â”‚   + Skip Connections      â”‚   â”‚
â”‚                           â”‚                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                  â”‚               â”‚
â”‚                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                              â”‚                               â”‚
â”‚                                              â–¼                               â”‚
â”‚                                    OUTPUT [batch, seq, dim]                  â”‚
â”‚                                                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  FIELD DYNAMICS (Updated during training)                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚                                                                               â”‚
â”‚  ğŸŒ¡ï¸ Temperature â”€â”€â–º Controls attention sharpness (lower = more focused)      â”‚
â”‚  ğŸ§² Coherence   â”€â”€â–º Measures neuron alignment (higher = more organized)       â”‚
â”‚  âš¡ Energy      â”€â”€â–º Triggers ruffle perturbations (prevents stagnation)       â”‚
â”‚                                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Mathematics

**Quaternion Representation:**
```
q = w + xi + yj + zk    where    wÂ² + xÂ² + yÂ² + zÂ² = 1
```

**Hamilton Product (Neuron Interaction):**
```
qâ‚ âŠ— qâ‚‚ = (wâ‚wâ‚‚ - xâ‚xâ‚‚ - yâ‚yâ‚‚ - zâ‚zâ‚‚) +
          (wâ‚xâ‚‚ + xâ‚wâ‚‚ + yâ‚zâ‚‚ - zâ‚yâ‚‚)i +
          (wâ‚yâ‚‚ - xâ‚zâ‚‚ + yâ‚wâ‚‚ + zâ‚xâ‚‚)j +
          (wâ‚zâ‚‚ + xâ‚yâ‚‚ - yâ‚xâ‚‚ + zâ‚wâ‚‚)k
```

**SLERP (Memory Blending):**
```
slerp(qâ‚, qâ‚‚, t) = sin((1-t)Î¸)/sin(Î¸) Â· qâ‚ + sin(tÎ¸)/sin(Î¸) Â· qâ‚‚
where Î¸ = arccos(qâ‚ Â· qâ‚‚)
```

**Geodesic Distance:**
```
d(qâ‚, qâ‚‚) = arccos(|qâ‚ Â· qâ‚‚|)
```

---

## ğŸ¯ Use Cases

<table>
<tr>
<td align="center" width="33%">
<h3>ğŸ¤– Robotics</h3>
<p>Pose estimation, motion planning, joint angle prediction</p>
</td>
<td align="center" width="33%">
<h3>ğŸ§¬ Molecular</h3>
<p>Protein folding, molecular docking, conformational analysis</p>
</td>
<td align="center" width="33%">
<h3>ğŸ® 3D Vision</h3>
<p>Object pose estimation, camera calibration, SLAM</p>
</td>
</tr>
<tr>
<td align="center" width="33%">
<h3>ğŸ›¸ Aerospace</h3>
<p>Satellite orientation, flight dynamics, trajectory prediction</p>
</td>
<td align="center" width="33%">
<h3>ğŸ¬ Animation</h3>
<p>Motion capture, skeletal animation, rotation interpolation</p>
</td>
<td align="center" width="33%">
<h3>ğŸ”¬ Physics</h3>
<p>Spin systems, quantum states, rotational dynamics</p>
</td>
</tr>
</table>

---

## ğŸ“š API Reference

### QRFModel

```python
class QRFModel(nn.Module):
    """
    Complete QRF model for end-to-end training.
    
    Parameters
    ----------
    input_dim : int
        Input feature dimension
    hidden_dim : int
        Hidden representation dimension
    output_dim : int
        Output dimension (use 4 for quaternion output)
    n_neurons : int, default=64
        Number of neurons in quaternion field
    use_attention : bool, default=True
        Enable quaternion-modulated attention
    use_sequence_memory : bool, default=True
        Enable cross-timestep sequence memory (NEW in v5.0)
    use_memory : bool, default=True
        Enable field state memory preservation
    """
```

### QuaternionRuffleField

```python
class QuaternionRuffleField(nn.Module):
    """
    Core quaternion field with dynamic neuron states.
    
    Attributes
    ----------
    coordinates : nn.Parameter
        Spatial positions [n_neurons, space_dim]
    quaternions : nn.Parameter  
        Rotational states [n_neurons, 4] (unit quaternions)
    field_temperature : torch.Tensor
        Adaptive temperature parameter
    coherence_factor : torch.Tensor
        Inter-neuron coupling strength
    
    Methods
    -------
    forward(update_dynamics=True)
        Compute dynamic distance matrix
    reset(preserve_memory=True)
        Reset field state
    restore_from_memory(blend_factor=0.5)
        SLERP restoration from memory
    compute_folding_energy()
        Calculate total field energy
    get_field_state_summary()
        Get state statistics dict
    """
```

### QuaternionRuffleOptimizer

```python
class QuaternionRuffleOptimizer:
    """
    Energy-based optimizer with adaptive perturbations.
    
    Parameters
    ----------
    field : QuaternionRuffleField
        The field to optimize
    fold_threshold : float, default=1.5
        Energy threshold for perturbations
    ruffle_scale : float, default=0.05
        Perturbation magnitude
    warmup_steps : int, default=20
        Steps before applying ruffles
    
    Methods
    -------
    step() -> Dict
        Apply ruffle step, returns stats dict with:
        - energy: Current field energy
        - temperature: Field temperature  
        - coherence: Field coherence
        - applied_ruffle: Whether perturbation was applied
    """
```

---

## ğŸ§ª Examples

### Rotation Prediction

```python
import torch
from quaternion_ruffle_field import QRFModel, QuaternionRuffleOptimizer

# Model for rotation prediction
model = QRFModel(
    input_dim=6,        # [original_xyz, rotated_xyz]
    hidden_dim=128,
    output_dim=4,       # quaternion
    n_neurons=64,
    use_attention=True,
    use_sequence_memory=True
)

# Quaternion loss function
def quaternion_loss(pred, target):
    pred = pred / pred.norm(dim=-1, keepdim=True)
    target = target / target.norm(dim=-1, keepdim=True)
    dot = (pred * target).sum(dim=-1)
    return (1.0 - torch.abs(dot)).mean()

# Training
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)
qrf_opt = QuaternionRuffleOptimizer(model.field)

for epoch in range(30):
    for points, rotations in dataloader:
        pred = model(points).mean(dim=1)  # Pool over sequence
        loss = quaternion_loss(pred, rotations)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        qrf_opt.step()
```

### Field Visualization

```python
from quaternion_ruffle_field import QuaternionMemoryTracer
import matplotlib.pyplot as plt

tracer = QuaternionMemoryTracer(model.field)

# Record during training
for epoch in range(100):
    tracer.record()
    # ... training step ...

# Plot evolution
history = tracer.export()
fig, axes = plt.subplots(1, 3, figsize=(12, 4))

axes[0].plot(history['energy'].numpy())
axes[0].set_title('Field Energy')

# Quaternion coherence over time
coherence = tracer.compute_memory_coherence()
print(f"Memory Coherence: {coherence:.4f}")
```

---

## ğŸ“„ Citation

If you use Quaternion Ruffle Field in your research, please cite:

```bibtex
@article{author2025quaternion,
  title={Quaternion Ruffle Field: Neural Networks with Orientational State},
  author={Your Name},
  journal={arXiv preprint arXiv:2025.XXXXX},
  year={2025},
  note={Achieves 92.6\% accuracy on 3D rotation prediction, 
        outperforming Transformers by 14\%}
}
```

---

## ğŸ¤ Contributing

We welcome contributions! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

```bash
# Development setup
git clone https://github.com/yourusername/quaternion-ruffle-field.git
cd quaternion-ruffle-field
pip install -e ".[dev]"
pytest tests/ -v
```

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) for details.

---

<p align="center">
  <b>â­ Star us on GitHub â€” it motivates us a lot!</b>
</p>

<p align="center">
  <a href="https://github.com/yourusername/quaternion-ruffle-field">
    <img src="https://img.shields.io/github/stars/yourusername/quaternion-ruffle-field?style=social" alt="GitHub stars">
  </a>
</p>

<p align="center">
  Made with â¤ï¸ and ğŸ”® quaternions
</p>